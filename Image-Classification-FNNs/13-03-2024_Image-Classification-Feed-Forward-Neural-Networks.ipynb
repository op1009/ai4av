{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09822c41",
   "metadata": {
    "id": "09822c41"
   },
   "source": [
    "# Image Classification with FNNs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b75e9",
   "metadata": {
    "id": "d67b75e9"
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ec164",
   "metadata": {
    "id": "4a0ec164"
   },
   "source": [
    "* Create a small feedforward neural network ([FNN](https://en.wikipedia.org/wiki/Feedforward_neural_network)) leveraging the TensorFlow [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras);\n",
    "* Train the FNN on the German Traffic Sign Recognition Benchmark ([GTSRB](https://benchmark.ini.rub.de/gtsrb_dataset.html)) dataset;\n",
    "* Visualise the training and validation metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58408470",
   "metadata": {
    "id": "58408470"
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1141e39",
   "metadata": {
    "id": "d1141e39"
   },
   "source": [
    "Here is a bit of [terminology](https://developers.google.com/machine-learning/glossary/) from the Google Machine Learning Glossary before we get started:\n",
    "* **Neural network**: a model composed of layers (at least one of which is [hidden](https://developers.google.com/machine-learning/glossary/#hidden_layer));\n",
    "\n",
    "* **Neuron**: a node in a neural network, typically taking in multiple input values and generating a single output value. The neuron calculates the output value by applying an [activation function](https://developers.google.com/machine-learning/glossary/#activation-function) to a weighted sum of input values;\n",
    "\n",
    "* **Perceptron**: _nodes_ in a deep neural network. Each perceptron takes in input values, runs an activation function over the weighted sum of values, and computes a single output value. A [backpropagation](https://developers.google.com/machine-learning/glossary/#backpropagation) algorithm is used to introduce feedback into the network;\n",
    "\n",
    "* **Feedforward Neural Network (FNN)**: a neural network without cyclic or recursive connections (e.g., a _deep neural network_, as opposed to a [recurrent neural network](https://developers.google.com/machine-learning/glossary/#recurrent_neural_network))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc5fd1-2c65-482d-9f44-159e87aef300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "!pip install tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307e4b7",
   "metadata": {
    "id": "7307e4b7"
   },
   "outputs": [],
   "source": [
    "### Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5062b0",
   "metadata": {
    "id": "9e5062b0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Generator, Iterator, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6265d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0a6265d9",
    "outputId": "213b62b9-12c7-46c2-c599-df9fbef8e231"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795433db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "795433db",
    "outputId": "d6fd43b8-7cdf-43cc-f769-83e2f3fbf06c"
   },
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b31353",
   "metadata": {
    "id": "32b31353"
   },
   "outputs": [],
   "source": [
    "### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb29ca9",
   "metadata": {
    "id": "6cb29ca9"
   },
   "outputs": [],
   "source": [
    "ENV_COLAB = False                # True if running in Google Colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c7533",
   "metadata": {
    "id": "0e3c7533"
   },
   "outputs": [],
   "source": [
    "# Root directory\n",
    "DIR_BASE = '' if not ENV_COLAB else '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31383a8f",
   "metadata": {
    "id": "31383a8f"
   },
   "outputs": [],
   "source": [
    "# Subdirectory to save output files\n",
    "DIR_OUT = os.path.join(DIR_BASE, 'out/')\n",
    "\n",
    "# Subdirectory pointing to input data\n",
    "DIR_SRC = os.path.join(DIR_BASE, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896082c5",
   "metadata": {
    "id": "896082c5"
   },
   "outputs": [],
   "source": [
    "### Creating subdirectories (if not exists)\n",
    "os.makedirs(DIR_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de99741",
   "metadata": {
    "id": "9de99741"
   },
   "source": [
    "### 1.1. Feedforward Neural Networks (FNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe5ebb",
   "metadata": {
    "id": "5afe5ebb"
   },
   "source": [
    "#### Types of FNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e93b6",
   "metadata": {
    "id": "d77e93b6"
   },
   "source": [
    "##### The single-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768097aa",
   "metadata": {
    "id": "768097aa"
   },
   "source": [
    "In its simplest form, a Feedforward Neural Network is a [single-layer perceptron](https://en.wikipedia.org/wiki/Feedforward_neural_network#Single-layer_perceptron). The single-layer perceptron is a network with only one input and one output layer. In [Exercise 1.3.2](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-3-2-Stochastic-Gradient-Descent/2022-08-29-Stochastic-Gradient-Descent.ipynb), we built a single-layer perceptron that consisted of a single input layer shaped by our input data (the image pixel attributes) and a single output layer (the predicted class distribution of probabilities). The output layer was computed directly from the sum of the product of the input layer units and the perceptron weights (plus a bias term). The output of the single-layer perceptron was then passed into an activation function (the softmax function), and a classification label was selected by choosing the prediction with the highest probability value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aedc61",
   "metadata": {
    "id": "33aedc61"
   },
   "source": [
    "The single-layer perceptron was a powerful yet simple type of Feedforward Neural Network architecture, but as a [linear classifier](https://en.wikipedia.org/wiki/Linear_classifier) it is only capable of learning linearly-separable patterns. As most functions are not linearly-seperable, we will consider a bit more involved approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a531e",
   "metadata": {
    "id": "704a531e"
   },
   "source": [
    "##### The multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3416e119",
   "metadata": {
    "id": "3416e119"
   },
   "source": [
    "What's better than _one_ layer of perceptrons? A ton of them!\n",
    "\n",
    "[Multi-layer perceptrons](https://en.wikipedia.org/wiki/Feedforward_neural_network#Multi-layer_perceptron) (MLPs) are a type of Feedforward Neural Network composed of many single-layer perceptrons. These perceptrons are organised into groups called _layers_. In a MLP, we introduce at least one _hidden_ layer composed of multiple perceptrons. These perceptrons in a hidden layer are not interconnected (i.e., no connections between each other in the same layer) but are said to be \"fully connected\" to the perceptrons in a preceding layer. In a hidden layer, these perceptrons also have activation functions, similar to the output layer in a single-layer perceptron.\n",
    "\n",
    "Like single-layer perceptrons, multi-layer perceptrons are trained by iteratively updating the weights and bias values in order to minimise an error (cost) function. Using _stochastic gradient descent_ to adjust these model parameters, we saw in Exercise 1.3.2 that, after a given number of epochs (passes) over our entire dataset, we were able to settle on semi-optimal weight $\\mathrm{w}$ and bias $\\mathrm{b}$ values.\n",
    "\n",
    "We can break the training phase into two primary steps with the multi-layer perceptron: a _forward pass_ and a _backwards_ pass. With a _forward_ pass over the data, each layer of perceptrons calculates a sum of products between the perceptron weights and the input values. The resulting values are then passed to an activation function (such as the _Rectified Linear Unit_ â€” [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))) where a single output value is generated. In a _backwards_ pass over over the network, we update the model parameters (the weights and bias values) using the partial derivative of an error function (like [cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression)). With the backpropagation algorithm, values calculated in the forward pass are used to compute the gradients for each of the model parameters. The \"backwards\" pass here indicates that the gradients are propagated back through the network starting from the output nodes to the nodes in the first hidden layer. The partial computations at each layer are used to update the weight values at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662f027",
   "metadata": {
    "id": "b662f027"
   },
   "source": [
    "### 1.2. TensorFlow Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf070e",
   "metadata": {
    "id": "33bf070e"
   },
   "source": [
    "[TensorFlow](https://www.tensorflow.org) is a very powerful, highly-optimised platform for machine learning. [Keras](https://github.com/keras-team/keras) is a high-level framework for the TensorFlow platform primarily authored by [FranÃ§ois Chollet](https://github.com/fchollet). While Keras used to support a several other backend compute engines, TensorFlow is now the only supported platform in Keras version 2.4+. With the release of TensorFlow 2.0 [came the announcement](https://blog.tensorflow.org/2018/12/standardizing-on-keras-guidance.html) that Keras would be the official high-level API for Google's TensorFlow. Together, the two make a great couple. While Keras focuses on simplistic, highly-readable and abstracted model creation, TensorFlow's full-fledged compute engine gives developers and practitioners the freedom to fine-tune much of their model's low-level implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c68220",
   "metadata": {
    "id": "01c68220"
   },
   "source": [
    "#### Modelling with the Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09b6ed",
   "metadata": {
    "id": "5b09b6ed"
   },
   "source": [
    "##### The `Sequential ` API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec21b7eb",
   "metadata": {
    "id": "ec21b7eb"
   },
   "source": [
    "In this exercise we will interface with the Keras through TensorFlow's [`Sequential`](https://www.tensorflow.org/guide/keras/sequential_model) API. In [Exercise 1.3.2](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-3-2-Stochastic-Gradient-Descent/2022-08-29-Stochastic-Gradient-Descent.ipynb) we demonstrated how to implement a model using TensorFlow Keras but didn't touch on many of Keras' core design principles. Given the simplicity of our network architecture, we will be using the Sequential API to model the multi-layer perceptron as a simple stack of layers. The `Sequential` model [approach](https://www.tensorflow.org/guide/keras/sequential_model) is good enough for us in this use case, but is **not appropriate** for any model architecture with:\n",
    "* multiple inputs or multiple outputs;\n",
    "* any amount of layers accepting multiple inputs or multiple outputs;\n",
    "* layer sharing;\n",
    "* a non-linear topology.\n",
    "\n",
    "Let's dive a bit more into the Keras abstraction and the classes we will use in our model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe43c5",
   "metadata": {
    "id": "8afe43c5"
   },
   "source": [
    "##### The `Layer` base class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6270e2a",
   "metadata": {
    "id": "e6270e2a"
   },
   "source": [
    "Now that we've learned a bit about multi-layer perceptrons, let's see how those layers can actually be implemented in TensorFlow. \n",
    "\n",
    "Every `Layer` instance in TensorFlow is born from the the Keras [`layers.Layer`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) base class. As said by Google themselves, \n",
    "\n",
    "\n",
    "_A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors. It involves **computation**, defined in the `call()` method, and a **state** (the weight variables) implemented in the `__init__()` method._\n",
    "\n",
    "A layer in our use case is a set of fully-connected (but not interconnected) units, each with a respective weight value. This _layer_ in a multi-layer perceptron also implements an activation function, and those weight values we discussed are also said to be _trainable_ (that is, that they can be modified during training). We will see that translating this into code using the Keras `Layer` API is a straightforward and easy process. \n",
    "\n",
    "With the `Layer` abstraction we also now have access to a whole set of methods and class attributes provided by TensorFlow to help us maintain, monitor, or modify layer state and layer variables during training and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bde66d",
   "metadata": {
    "id": "79bde66d"
   },
   "source": [
    "##### The `Model` base class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a156719",
   "metadata": {
    "id": "9a156719"
   },
   "source": [
    "A [`Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) groups `Layer`s into a single object while also providing many powerful training and inference features. A `Model` can be initialised in a single line of code and begin providing insane functionality right off-the-shelf. Remember that exhausting [training and validation loop](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Object-Detection-in-Urban-Environments/Exercises/1-3-2-Stochastic-Gradient-Descent/2022-08-29-Stochastic-Gradient-Descent.ipynb) we wrote in the last exercise? With a `Model` instance, we can shorten that entire functionality into just _one line of code_ using the `Model.fit()` method.\n",
    "\n",
    "One other way to use ` Model` is to [_subclass it_](https://www.tensorflow.org/guide/keras/custom_layers_and_models). In other words, we can create a class that inherits `Model` and from there customise much of the core Keras functionality to suit our own needs. This can be beneficial for those wanting full control over the [lower-level](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#going_lower-level) details of the training cycle, or for those who want to encapsulate complex model architectures, custom callbacks, metric functions, etc. into neat, [serialisable](https://www.tensorflow.org/guide/keras/save_and_serialize/) Model objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd02b2",
   "metadata": {
    "id": "1ddd02b2"
   },
   "source": [
    "#### Training and validation with the Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae492f7",
   "metadata": {
    "id": "8ae492f7"
   },
   "source": [
    "##### The `compile()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e186510",
   "metadata": {
    "id": "2e186510"
   },
   "source": [
    "This `Model` class method is essential for putting together all the pieces in building a model. The [`compile()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) API allows us to quickly initialise our model instance with all sorts of useful [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), [metric](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) and [loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses) functions and be up and running in no time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de14c0",
   "metadata": {
    "id": "62de14c0"
   },
   "source": [
    "##### The `fit()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cbd46f",
   "metadata": {
    "id": "d6cbd46f"
   },
   "source": [
    "The `Model` [`fit()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method is at the heart of our model training process. This class method provides us with all the parameters we need to go from a hollow, untrained model to a fully-trained object detector, image classifier, etc. Our model hyperparameters â€” the _batch size_, _epochs_, etc. are supplied as input parameters into this method along with our dataset and any considerations we have for it (e.g., whether to `shuffle` the input data, perform a `validation_split` over it, etc.). Lastly, here in the model `fit()` method is where we supply any `callbacks` we want to include alongside the training process.\n",
    "\n",
    "Once your input parameters are good to go, training a model is really just as simple as executing this line of code. The `fit()` method will even handle printing out updates to the console for you â€” a nice progress bar and some helpful metrics at every iteration of training. No wonder Keras has been [such a hit](https://blog.tensorflow.org/2018/12/standardizing-on-keras-guidance.html) at Google!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790689c",
   "metadata": {
    "id": "9790689c"
   },
   "source": [
    "##### The `callbacks` functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398417d5",
   "metadata": {
    "id": "398417d5"
   },
   "source": [
    "In addition to the benefits aforementioned when using the Keras `fit()` API for training, we also get the ability to specify [`callbacks`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback). Callbacks are functions that get passed into the `fit()`, `evaluate()` and `predict()` methods of a model in order to customise their functionality or run your own code on regular intervals (e.g., at the end of each epoch). While some callback functionality is baked in by default (e.g., [`callbacks.History`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)), several other popular callbacks exist. One of those is the [`callbacks.LearningRateScheduler`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler) which serves as a base class for all custom learning rate schedulers (e.g., [`optimizers.schedules.ExponentialDecay`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler)). Through [_subclassing_](https://www.tensorflow.org/guide/keras/custom_layers_and_models) we can override some of the callback methods and provide our own to do things like update our model's learning rate using a custom function on every epoch, for example. \n",
    "\n",
    "One last callback worth mentioning here for our own use is [`callbacks.TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard). This callback allows our model to log certain events throughout the training process, such as metrics summaries or weight updates, in order to visualise them in detail during the training cycle. The [TensorBoard dashboard](https://www.tensorflow.org/tensorboard/get_started) provides a nice graphical interface to monitor real-time, interactive plots, graphs and charts of important training metrics and other stats. We can even use these real-time plots in TensorBoard to [visualise layer weights](http://cs231n.github.io/understanding-cnn/) or [monitor confusion matrices](https://www.tensorflow.org/tensorboard/image_summaries#building_an_image_classifier) on each epoch, all with the help of callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50707f5b",
   "metadata": {
    "id": "50707f5b"
   },
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852dc50e",
   "metadata": {
    "id": "852dc50e"
   },
   "source": [
    "From the Introduction you by now should have a decent overview of TensorFlow and some of the essential functionality Keras brings to it. In this section, we will implement a Feedforward Neural Network (FNN) for image classification on the German Traffic Sign Recognition (GTSRB), starting with a simple `Sequential` model architecture and adding complexity from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e45ce5",
   "metadata": {
    "id": "27e45ce5"
   },
   "source": [
    "### 2.1. Feedforward Neural Networks (FNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0b8e9",
   "metadata": {
    "id": "aae0b8e9"
   },
   "source": [
    "The neural network you create should have less than 4 layers, including the output layer. This last layer should not be activated. Take the time to experiment with different architecture (number of layers, number of neurons) and see how it impacts the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1602b",
   "metadata": {
    "id": "1df1602b"
   },
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32f1b7",
   "metadata": {
    "id": "ac32f1b7"
   },
   "outputs": [],
   "source": [
    "def create_network(\n",
    "        input_shape: Tuple[int, int, int], output_shape: int, \n",
    "        model_name: str='FeedforwardNeuralNetwork') -> tf.keras.Model:\n",
    "    \"\"\"Creates a simple Feedforward Neural Network.\n",
    "    \n",
    "    :param input_shape: a tuple describing the image shape\n",
    "        without considering the batch size dimension.\n",
    "    :param output_shape: an integer value of the number of distinct classes.\n",
    "    :param model_name: a string describing the model name.\n",
    "    :returns: a tf.keras.Model instance, a FNN built using the TensorFlow\n",
    "        Keras Sequential API model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(output_shape)], \n",
    "        name=model_name\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55462b3e",
   "metadata": {
    "id": "55462b3e"
   },
   "outputs": [],
   "source": [
    "### Defining our model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86833c8",
   "metadata": {
    "id": "f86833c8"
   },
   "outputs": [],
   "source": [
    "model_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e8e5c",
   "metadata": {
    "id": "c57e8e5c"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 32                                     # Each RGB image has 32x32 px resolution\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)               # Each RGB image has 3 channels (R,G,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac361e51",
   "metadata": {
    "id": "ac361e51"
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 43                                    # The GTSRB has 43 distinct classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861f028",
   "metadata": {
    "id": "d861f028"
   },
   "outputs": [],
   "source": [
    "model_params.update({'input_shape': IMG_SHAPE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f57bcc",
   "metadata": {
    "id": "40f57bcc"
   },
   "outputs": [],
   "source": [
    "model_params.update({'n_classes': N_CLASSES})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821a566",
   "metadata": {
    "id": "6821a566"
   },
   "outputs": [],
   "source": [
    "model_params.update({'model_name': 'FeedforwardNeuralNetwork'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7e43e",
   "metadata": {
    "id": "e1a7e43e"
   },
   "outputs": [],
   "source": [
    "### Initialising the FNN\n",
    "model = create_network(input_shape=model_params['input_shape'],\n",
    "                       output_shape=model_params['n_classes'],\n",
    "                       model_name=model_params['model_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YtvCnnCjn9IV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtvCnnCjn9IV",
    "outputId": "b069c366-c6fe-40a7-c9d9-7536ebc384f5"
   },
   "outputs": [],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JknsNA9Hoj0m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JknsNA9Hoj0m",
    "outputId": "ddd02ad9-3a48-43f4-8d00-bb7a4be35b6f"
   },
   "outputs": [],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b444a",
   "metadata": {
    "id": "7b6b444a"
   },
   "source": [
    "### 2.2. Modelling with TensorFlow Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2f31b",
   "metadata": {
    "id": "18f2f31b"
   },
   "outputs": [],
   "source": [
    "### Defining our optimizer hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186de24",
   "metadata": {
    "id": "1186de24"
   },
   "outputs": [],
   "source": [
    "model_params.update({'learning_rate': 1e-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee8ab3",
   "metadata": {
    "id": "19ee8ab3"
   },
   "outputs": [],
   "source": [
    "decay = False                                     # Whether or not to use a learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da8838",
   "metadata": {
    "id": "d4da8838"
   },
   "outputs": [],
   "source": [
    "initial_lr = model_params['learning_rate']\n",
    "decay_rate = 0.96                                 # Amount to decay learning rate by (decrease by 96%)\n",
    "decay_steps = 128 * 10                            # When to modify learning rate (every interval of `decay_steps`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f6385",
   "metadata": {
    "id": "728f6385"
   },
   "outputs": [],
   "source": [
    "### Initialising a learning rate schedule\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc2792",
   "metadata": {
    "id": "e5bc2792"
   },
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                        initial_learning_rate=initial_lr,\n",
    "                        decay_steps=decay_steps,\n",
    "                        decay_rate=decay_rate,\n",
    "                        staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49d29f",
   "metadata": {
    "id": "af49d29f"
   },
   "outputs": [],
   "source": [
    "model_params.update({'lr_schedule': lr_schedule})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d882d",
   "metadata": {
    "id": "1b9d882d"
   },
   "outputs": [],
   "source": [
    "### Selecting the optimiser and activation functions \n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282b0d5",
   "metadata": {
    "id": "1282b0d5"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "                learning_rate=model_params['learning_rate'] if not decay else (\n",
    "                              model_params['lr_schedule']),\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-07,\n",
    "                amsgrad=False,\n",
    "                name='Adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e822f7b",
   "metadata": {
    "id": "1e822f7b"
   },
   "outputs": [],
   "source": [
    "### Choosing the loss and performance metrics\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69a865d",
   "metadata": {
    "id": "d69a865d"
   },
   "outputs": [],
   "source": [
    "# Here we specify `from_logits=True` since we are not using the \n",
    "# 'softmax' activation function in the last layer of our model\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b9c98",
   "metadata": {
    "id": "4e3b9c98"
   },
   "outputs": [],
   "source": [
    "accuracy_fn = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8845a7e",
   "metadata": {
    "id": "a8845a7e"
   },
   "outputs": [],
   "source": [
    "### Compiling the model using the `compile()` API\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wAQikA5-PGyN",
   "metadata": {
    "id": "wAQikA5-PGyN"
   },
   "outputs": [],
   "source": [
    "# Here we use the stock 'adam' optimizer for best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f7ffc",
   "metadata": {
    "id": "745f7ffc"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6743cc",
   "metadata": {
    "id": "8e6743cc"
   },
   "source": [
    "### 2.3. Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96776b0",
   "metadata": {
    "id": "d96776b0"
   },
   "outputs": [],
   "source": [
    "### Setting the training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0879d4f",
   "metadata": {
    "id": "b0879d4f"
   },
   "outputs": [],
   "source": [
    "model_params.update({'epochs': 20})\n",
    "# Using batch size of 128 (mini-batching as in D. Kingma, 2015)\n",
    "model_params.update({'batch_size': 128})\n",
    "model_params.update({'shuffle': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fb0c6",
   "metadata": {
    "id": "805fb0c6"
   },
   "outputs": [],
   "source": [
    "### Usage of the `callbacks()` method\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765d8fe",
   "metadata": {
    "id": "a765d8fe"
   },
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b4bcd",
   "metadata": {
    "id": "f13b4bcd"
   },
   "outputs": [],
   "source": [
    "def get_module_logger(mod_name: str) -> logging.Logger:\n",
    "    \"\"\"Initialises a console logger instance.\n",
    "    \n",
    "    :param mod_name: the model name to assign to the logger.\n",
    "    :returns: a logger instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Setting up the console logger and formatter\n",
    "    logger = logging.getLogger(mod_name)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    ### Prevent messages going to root handler\n",
    "    logger.propagate = False\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521c2e4",
   "metadata": {
    "id": "d521c2e4"
   },
   "outputs": [],
   "source": [
    "logger = get_module_logger(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cb909",
   "metadata": {
    "id": "cc8cb909"
   },
   "source": [
    "### 2.4. Evaluation on the GTSRB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9020fb",
   "metadata": {
    "id": "6f9020fb"
   },
   "source": [
    "#### Considerations for our input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79902f44",
   "metadata": {
    "id": "79902f44"
   },
   "outputs": [],
   "source": [
    "### Defining our input image specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8712a6e",
   "metadata": {
    "id": "c8712a6e"
   },
   "outputs": [],
   "source": [
    "image_size = (32, 32)          # Each RGB image has 32x32 px resolution\n",
    "n_features = (32 * 32) * 3     # Each pixel value is considered an attribute (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kESR1SPhcQ_g",
   "metadata": {
    "id": "kESR1SPhcQ_g"
   },
   "outputs": [],
   "source": [
    "model_params.update({'image_size': image_size})\n",
    "model_params.update({'n_features': n_features})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36427be",
   "metadata": {
    "id": "a36427be"
   },
   "source": [
    "#### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcf502",
   "metadata": {
    "id": "e5bcf502"
   },
   "source": [
    "##### Fetching the GTSRB data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a037552",
   "metadata": {
    "id": "1a037552"
   },
   "source": [
    "You will need to specify the `--imdir`, e.g. `--imdir GTSRB/Final_Training/Images/`, using the provided GTSRB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561a2ae",
   "metadata": {
    "id": "f561a2ae"
   },
   "outputs": [],
   "source": [
    "# imdir = os.path.join(DIR_SRC, 'GTSRB/Final_Training/Images')\n",
    "print(DIR_SRC)\n",
    "imdir = os.path.join(DIR_SRC, 'GTSRB/Final_Training/Images')\n",
    "print(imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p5o10jcdcL6M",
   "metadata": {
    "id": "p5o10jcdcL6M"
   },
   "outputs": [],
   "source": [
    "model_params.update({'imdir': imdir})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce72a2",
   "metadata": {
    "id": "81ce72a2"
   },
   "source": [
    "The following `get_datasets()` method returns a tuple of [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) instances containing the training and validation datasets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fae16e",
   "metadata": {
    "id": "a1fae16e"
   },
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b50208",
   "metadata": {
    "id": "39b50208"
   },
   "outputs": [],
   "source": [
    "def get_datasets(imdir: str) -> tuple:\n",
    "    \"\"\"Return the training and validation datasets.\n",
    "    \n",
    "    :param imdir: absolute path to the directory where the data is stored in.\n",
    "    :returns: (train_dataset, validation_dataset), tuple of tf.data.Dataset instances.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                        imdir,\n",
    "                        labels='inferred',\n",
    "                        label_mode='int',\n",
    "                        color_mode='rgb',\n",
    "                        batch_size=model_params.get('batch_size', 1),\n",
    "                        image_size=model_params.get('image_size', (32, 32)),\n",
    "                        shuffle=True,\n",
    "                        seed=123,\n",
    "                        validation_split=0.1,\n",
    "                        subset='training',\n",
    "    )\n",
    "    validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                        imdir,\n",
    "                        labels='inferred',\n",
    "                        label_mode='int',\n",
    "                        color_mode='rgb',\n",
    "                        batch_size=model_params.get('batch_size', 1),\n",
    "                        image_size=model_params.get('image_size', (32, 32)),\n",
    "                        shuffle=True,\n",
    "                        seed=123,\n",
    "                        validation_split=0.1,\n",
    "                        subset='validation',\n",
    "    )\n",
    "    return train_dataset, validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906cdf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f906cdf7",
    "outputId": "d6d80f2e-3e36-4083-fb42-d43063553e06"
   },
   "outputs": [],
   "source": [
    "### Fetching the training and validation datasets\n",
    "train_dataset, validation_dataset = get_datasets(model_params['imdir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f368f0",
   "metadata": {
    "id": "b7f368f0"
   },
   "source": [
    "##### Processing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936d2612",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "936d2612",
    "outputId": "17959dbe-f74c-4a1e-d801-0d3239d72a4d"
   },
   "outputs": [],
   "source": [
    "### Number of features (pixel values) in a single image\n",
    "train_iter = iter(train_dataset)\n",
    "len(train_iter.get_next()[0][0].numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7a1ba",
   "metadata": {
    "id": "55d7a1ba"
   },
   "outputs": [],
   "source": [
    "def process(dataset: tf.data.Dataset) -> Generator[tuple, None, None]:\n",
    "    \"\"\"Processes the input dataset and returns a generator object.\n",
    "\n",
    "    :param dataset: the tf.data.Dataset instance of batched image, label data.\n",
    "    :returns: the generator instance modifying the image attribute values.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_generator() -> Iterator[Tuple[tf.Tensor, tf.Tensor]]:\n",
    "        \"\"\"Scales the input image data.\n",
    "        \n",
    "        Unbatches the tf.data.Dataset and scales all image attributes,\n",
    "        i.e., pixel values, in the range [0, 1].\n",
    "\n",
    "        :returns: an iterator yielding the modfied image data and\n",
    "            corresponding label.\n",
    "        \"\"\"\n",
    "\n",
    "        for batch in dataset:\n",
    "            for image, label in zip(*batch):\n",
    "                image = tf.cast(image/255. ,tf.float32)\n",
    "                yield image, label\n",
    "    return process_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba04d8a",
   "metadata": {
    "id": "1ba04d8a"
   },
   "outputs": [],
   "source": [
    "### Unbatching the datasets and scaling the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HDZQst2ndToS",
   "metadata": {
    "id": "HDZQst2ndToS"
   },
   "outputs": [],
   "source": [
    "train_dataset_scaled = tf.data.Dataset.from_generator(\n",
    "                                generator=process(train_dataset), \n",
    "                                output_types=(tf.float32, tf.int32), \n",
    "                                output_shapes=(model_params['input_shape'], ())\n",
    ").batch(model_params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8SjK-vPPkl0I",
   "metadata": {
    "id": "8SjK-vPPkl0I"
   },
   "outputs": [],
   "source": [
    "validation_dataset_scaled = tf.data.Dataset.from_generator(\n",
    "                                generator=process(validation_dataset), \n",
    "                                output_types=(tf.float32, tf.int32), \n",
    "                                output_shapes=(model_params['input_shape'], ())\n",
    ").batch(model_params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6pKpKa63Mj7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6pKpKa63Mj7",
    "outputId": "2307a354-ed8a-4b9f-9415-1f4e1f554c2a"
   },
   "outputs": [],
   "source": [
    "type(validation_dataset_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df3c87",
   "metadata": {
    "id": "13df3c87"
   },
   "source": [
    "##### Performing the training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084541c8",
   "metadata": {
    "id": "084541c8"
   },
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R_8JpK72lDjc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_8JpK72lDjc",
    "outputId": "dcc15a8d-323b-466b-cf4a-8557de0554eb"
   },
   "outputs": [],
   "source": [
    "logger.info(f\"\\nTraining for {model_params['epochs']} epochs \" + \n",
    "            f\"using '{model_params['imdir']}' data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd3d2a",
   "metadata": {
    "id": "dfcd3d2a"
   },
   "outputs": [],
   "source": [
    "### Usage of the `fit()` API\n",
    "# See: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d99992",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90d99992",
    "outputId": "2d64de60-b0e7-4bb0-babe-cc498a014f42",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "                x=train_dataset_scaled,\n",
    "                epochs=model_params.get('epochs', 10),\n",
    "                batch_size=model_params.get('batch_size', 128),\n",
    "                validation_data=validation_dataset_scaled,\n",
    "                shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ee915",
   "metadata": {
    "id": "ce2ee915"
   },
   "source": [
    "##### Visualising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f0c64",
   "metadata": {
    "id": "e79f0c64"
   },
   "source": [
    "Lastly, at the end of training, you will need to be in the `Desktop` view to see the metrics visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7de8ff",
   "metadata": {
    "id": "ad7de8ff"
   },
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81537bd8",
   "metadata": {
    "id": "81537bd8"
   },
   "outputs": [],
   "source": [
    "def display_metrics(history: tf.keras.callbacks.History):\n",
    "    \"\"\"Plots the per-epoch loss and accuracy metrics.\n",
    "    \n",
    "    :param history: the Keras `callbacks.History` object.\n",
    "    \"\"\"\n",
    "    \n",
    "    f, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax[0].plot(history.history['loss'], linewidth=3)\n",
    "    ax[0].plot(history.history['val_loss'], linewidth=3)\n",
    "    ax[0].set_title('Loss', fontsize=16)\n",
    "    ax[0].set_ylabel('Loss', fontsize=16)\n",
    "    ax[0].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[0].legend(['train loss', 'val loss'], loc='upper right')\n",
    "    ax[1].plot(history.history['accuracy'], linewidth=3)\n",
    "    ax[1].plot(history.history['val_accuracy'], linewidth=3)\n",
    "    ax[1].set_title('Accuracy', fontsize=16)\n",
    "    ax[1].set_ylabel('Accuracy', fontsize=16)\n",
    "    ax[1].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[1].legend(['train acc', 'val acc'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KcDGiPjjXxex",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcDGiPjjXxex",
    "outputId": "d393c287-4325-4305-d235-3ecf3beabfe6"
   },
   "outputs": [],
   "source": [
    "# type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afcecf",
   "metadata": {
    "id": "28afcecf"
   },
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43b93a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "8d43b93a",
    "outputId": "93a81a56-612e-486b-a8b0-34965e46bbb7"
   },
   "outputs": [],
   "source": [
    "# display_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72d178-42c7-436d-8473-9500879f59d5",
   "metadata": {},
   "source": [
    "##### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e98c19-e993-49f9-8a5a-1e54a310d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a `.keras` zip archive.\n",
    "model_path = os.path.join(DIR_OUT, 'gtsrb_model.keras')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ef983-0ce4-4b26-96fe-a24fe293eaf9",
   "metadata": {},
   "source": [
    "### 2.5 Testing\n",
    "---\n",
    "#### Only class prediction is tested without IoU consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950a804-80bb-4f9a-90fe-597fbe15a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "my_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Show the model architecture\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18bbc49-1e2b-45f5-992b-9c6d144910c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions from model https://keras.io/api/data_loading/image/\n",
    "\n",
    "i=0\n",
    "\n",
    "filenames_list = []\n",
    "input_array = []\n",
    "\n",
    "for img in glob.glob(\"data/GTSRB/Final_Test/Images/*.png\"):\n",
    "    i += 1\n",
    "\n",
    "    # test for 500 images only, running on CPU\n",
    "    if i > 500:\n",
    "        break\n",
    "        \n",
    "    test_img = tf.keras.utils.load_img(\n",
    "        img,\n",
    "        color_mode=\"rgb\",\n",
    "        target_size=(32, 32),\n",
    "        interpolation=\"nearest\",\n",
    "        keep_aspect_ratio=False,)\n",
    "\n",
    "    img_arr = tf.keras.utils.img_to_array(test_img)\n",
    "    input_array.append(img_arr)\n",
    "    filenames_list.append(os.path.basename(img))\n",
    "    # filenames.append(img)\n",
    "\n",
    "# print(len(input_array))\n",
    "input_arr = np.array(input_array)\n",
    "predictions = my_model.predict(input_arr)\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62debc27-4a7c-4849-ac26-dadb11439f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to dict of filenames and predictedClassId\n",
    "predictions_list = list(predictions.argmax(axis=1))\n",
    "predicted_dict = {}\n",
    "\n",
    "for fn,p in zip(filenames_list, predictions_list):\n",
    "    predicted_dict[fn] = p\n",
    "\n",
    "# predicted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b41841-7b6f-406b-b9b9-a84f209f28c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred_df = pd.DataFrame(predicted_dict.items(), columns=['Filename', 'Prediction'])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944f059-1891-43d2-99f6-3e2818c13c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSVFILE='data/GTSRB/Final_Test/GT-final_test.csv'\n",
    "gt_df=pd.read_csv(CSVFILE, delimiter=';')\n",
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a7a51-07e2-4007-a8cc-3612db5848ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(gt_df, pred_df, how='inner', on='Filename')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14287757-3ef2-4ff4-b9b3-5ef26b090fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "gtValue = merged_df['ClassId']\n",
    "predValue = merged_df['Prediction']\n",
    "\n",
    "gtValue = gtValue.values\n",
    "predValue = predValue.values\n",
    "\n",
    "cmt = confusion_matrix(gtValue, predValue)\n",
    "# print(cmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b243653-a477-4ab2-b307-3df3cb57f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(55, 55))\n",
    "# plt.figure(figsize=(10,6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmt, display_labels=model_params['n_classes'])\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('fig.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tK737Qp2Pc_f",
   "metadata": {
    "id": "tK737Qp2Pc_f",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Closing Remarks\n",
    "\n",
    "##### Alternatives\n",
    "* Try out other Keras [`optimizers`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), \n",
    "e.g., [RMSprop](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop);\n",
    "* Add additional `Layer`s (e.g., [`Dropout`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)) or modify exisiting `Dense` layers (e.g., the number of unts).\n",
    "\n",
    "##### Extensions of task\n",
    "* Use [`TensorBoard`](https://www.tensorflow.org/tensorboard/get_started) to visualise weight updates during training;\n",
    "* Run the trained model on test set and plot a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) to visualise class prediction scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Q5rMWchRaoD",
   "metadata": {
    "id": "6Q5rMWchRaoD"
   },
   "source": [
    "## 4. Future Work\n",
    "\n",
    "- âœ… Create more complex model architectures for image classification (e.g., a [Convolutional Neural Network](https://www.tensorflow.org/tutorials/images/cnn) â€” see [Exercise 1.4.2](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-4-2-Building-Custom-CNNs/2022-09-12-Building-Custom-Convolutional-Neural-Networks.ipynb));\n",
    "- âœ… Track evaluation metrics (e.g., F1-score, precision/recall â€” see [Exercise 1.5.2](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-5-2-Mean-Average-Precision/2022-09-25-Mean-Average-Precision.ipynb));\n",
    "- âœ… Evaluate trained model on test dataset (e.g., Waymo Open Dataset â€” see [Project 1.1: Report](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/1-1-Object-Detection-in-Urban-Environments/2022-10-16-Report.md));\n",
    "- âœ… Use TensorBoard to visualise updates during training (e.g., losses and evaluation metrics â€” see [Project 1.1: Report](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/1-1-Object-Detection-in-Urban-Environments/2022-10-16-Report.md))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8378fa",
   "metadata": {
    "id": "4b8378fa"
   },
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd2d4b5",
   "metadata": {
    "id": "9fd2d4b5"
   },
   "source": [
    "The base notebook is used from [GitHub - Jonathan Moran](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-3-3-Image-Classification-FNNs/2022-09-05-Image-Classification-Feed-Forward-Neural-Networks.ipynb)\n",
    "\n",
    "References\n",
    "* [1] Kingma, D. and Ba, J. Adam: A Method for Stochastic Optimization. arXiv (2014). [doi:10.48550/arXiv.1412.6980](https://arxiv.org/abs/1412.6980v9).\n",
    "\n",
    "\n",
    "Helpful resources:\n",
    "* [Feedforward Neural Networks | Brilliant.org](https://brilliant.org/wiki/feedforward-neural-networks/)\n",
    "* [Standardizing on Keras: Guidance on High-level APIs in TensorFlow 2.0 | Google TensorFlow Blog](https://blog.tensorflow.org/2018/12/standardizing-on-keras-guidance.html)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5afe5ebb",
    "b662f027",
    "01c68220",
    "1ddd02b2"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
